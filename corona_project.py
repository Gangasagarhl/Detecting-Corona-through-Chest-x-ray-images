# -*- coding: utf-8 -*-
"""Corona Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JboSWmatQDD7gsx1cPlh6-5JJilpo61F
"""

# for mounting google drive
from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import seaborn as sns
import os
import numpy as np
import matplotlib.pyplot as plt
import cv2
#Tensorflow Keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,confusion_matrix
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Conv2D,Dropout,Activation,Flatten
from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint

data_path = '/content/drive/My Drive/Datasets/Data sets images/COVID 19 Project'


categories = os.listdir(data_path)#listing the directories or folders insede the file path
label = [i for i in range(len(categories))] # Numerical labels in category
category_dictionary = {} # for holding the mapping values from numeraical to category 
dictionary={}# Mapping

for i in range(len(label)):
    category_dictionary[i] = categories[i]
    dictionary[categories[i]] = i

    
# Printing data inside variable
print("Category: ",categories)
print("Labels: ",label)
print("Category Dictionary: ",category_dictionary)
print("Dictionary: ",dictionary)

def glance(cls,num):
    
    temp = os.listdir(data_path +'/'+ categories[cls] )[num]# this gets the image name in directory    
    img_path = data_path +'/'+ categories[cls]+'/'+ temp # image path within direcory
    image = plt.imread(img_path) #reads image
    plt.imshow(image) # shows or prints image
    
    print("Shape of Image:",image.shape)

print("Normal Chest X ray")
glance(1,16)

print("Corona Affected Chest")
glance(0,10)

def mean_dimension_500(cls):
    dim1 = []
    dim2 = []
    path = data_path +'/'+ categories[cls]
    images_name = os.listdir(path)
    
    print('Calculating, Kindly Wait For Some Minutes.....')
    img=''

    for i in images_name[300:800]:
        
        path_img = path + '/' + i 
        img = plt.imread(path_img)
        d1,d2 = img.shape[:2]
        dim1.append(d1)
        dim2.append(d2)

    
    sns.jointplot(dim1,dim2)
    plt.show()
        
    print("Img Max:",img.max())
    print("Img Min:",img.min())
    
    print("dim1 mean:",np.mean(dim1))
    print("dim2 mean:",np.mean(dim2))

    print("Last Image's shape:",img.shape)
    
    
    
    return dim1,dim2

dim1,dim2 = mean_dimension_500(0)

### Image data For Training Neural Network

# checking temporarily, whether it is going to work or not
temp_path = data_path +'/'+ categories[1]
img_name_temp = os.listdir(temp_path)[1]

img_temp = cv2.imread(temp_path + '/' + img_name_temp)
print("Actual",img_temp.shape)
plt.imshow(img_temp)
plt.show()



img_temp = cv2.cvtColor(img_temp,cv2.COLOR_BGR2GRAY)
print("Gray",img_temp.shape)
plt.imshow(img_temp)
plt.show()

image_data_x = []
category_y = []
dim = (int(np.mean(dim1)),int(np.mean(dim2)))
print(dim,type(dim))

for i in categories:
    for j in os.listdir(data_path +'/'+ i):
        path_trace = data_path +'/'+ i+'/'+j
        img = cv2.imread( path_trace )
        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)    
        img = cv2.resize(img,(200,200)) 
        image_data_x.append(img)
        category_y.append(dictionary[i])

# Getting to know shape
image_data_x = np.array(image_data_x)
category_y   = np.array(category_y)

image_data_x.shape,category_y.shape

print(category_y[18])
plt.imshow(image_data_x[18])

# splitting data to train and test
image_data_x = image_data_x.reshape(-1,200,200,1)
x_train,x_test,y_train,y_test = train_test_split(image_data_x,category_y, test_size = 0.2,random_state=42)

y_train_cat = to_categorical(y_train)
y_test_cat = to_categorical(y_test)

def shape():
    print("train,test,cat")
    print(x_train.shape,y_train.shape,x_test.shape,y_test.shape,y_train_cat.shape,y_test_cat.shape)
    
shape()

### Building Sequential model
model =  Sequential()

model.add(Conv2D(filters=64,kernel_size = (2,2),padding = 'same',activation = 'relu',input_shape=(200,200,1)))
model.add(Conv2D(filters=128,kernel_size = (2,2),padding = 'same',activation = 'relu'))
model.add(Dropout(0.4))

model.add(Conv2D(filters=128,kernel_size = (2,2),padding = 'same',activation = 'relu'))
model.add(Conv2D(filters=128,kernel_size = (2,2),padding = 'same',activation = 'relu'))
model.add(Dropout(0.5))

model.add(Conv2D(filters=256,kernel_size = (2,2),padding = 'same',activation = 'relu'))
model.add(Dropout(0.4))

model.add(Conv2D(filters=64,kernel_size = (2,2),padding = 'same',activation = 'relu'))
model.add(Dropout(0.5))

model.add(Flatten())


model.add(Dense(2))
model.add(Activation('softmax'))

model.compile(optimizer = 'adam',loss='categorical_crossentropy', metrics=['accuracy'])

es =  EarlyStopping(monitor='val_loss', patience=10, mode='min')

MC=ModelCheckpoint(
    filepath='/content/drive/My Drive/Datasets/Data sets images/COVID 19 Project/Model_checkpoints', 
    monitor='val_loss', 
    verbose=0, 
    save_best_only=True,
    save_weights_only=False, 
    mode='min', 
    save_freq='epoch', 
    options=None, 
)

help(ModelCheckpoint)

model.summary()

model.fit(x=x_train,y=y_train_cat,epochs=300,callbacks=[es,MC],validation_data=(x_test,y_test_cat),batch_size=(16))

predictions = model.predict_classes(x_test)

print(classification_report(y_test,predictions))

confusion_matrix(y_test,predictions)

#Testing model with data
def testing_model(num):
  if num < len(x_test):
    original_label = category_dictionary[y_test[num]]
    img = x_test[num]
    prediction = model.predict_classes(img.reshape(-1,200,200,1))
    prediction = category_dictionary[prediction[0]]
    print("Original Label: ",original_label)
    print("Predicted Label: ",prediction)

    plt.imshow(img.reshape(200,200))
    plt.show()

  else:
    print("Number given is not Valid, please Enter Valid ones")

testing_model(103)



model.save("/content/drive/My Drive/Datasets/Data sets images/COVID 19 Project/covid19_project.h5")